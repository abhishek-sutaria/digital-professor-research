# ğŸ” Intelligent Data Scraper - Digital Professor Research

> **AI-Powered Person Profile Builder** - Creates 30-50 page professional profiles for LLM training by scraping, synthesizing, and structuring comprehensive knowledge about marketing experts.

## ğŸ¯ Overview

This tool automatically constructs a complete digital profile of a person (specifically marketing professionals) by:
- Scraping data from 7+ sources (Google Scholar, Wikipedia, News, YouTube, GitHub, LinkedIn, University sites)
- Using AI (Google Gemini) to synthesize 12-15 page knowledge sections
- Generating a professional PDF + ZIP of research papers
- Implementing strict author disambiguation to avoid "Kevin Welding" pollution

Perfect for building LLM training data, digital twins, or comprehensive knowledge bases.

## ğŸš€ Key Features

### 1. **Identity Lock & Author Disambiguation** ğŸ”’
- Prevents mixing with other people who share the same name
- Locks to specific Google Scholar ID
- Filters publications by exact name + affiliation keywords
- Only includes verified content

### 2. **AI-Powered Synthesis** ğŸ¤–
- Uses Google Gemini to create 12-15 page knowledge narratives
- Synthesizes: Domain Expertise, Personality, Writing Style, Leadership, Network Influence
- Chunked map-reduce approach for reliable generation
- Fallback synthesis to avoid empty sections

### 3. **Multi-Source Intelligence** ğŸ“Š
Scrapes from:
- Google Scholar (research papers + citations)
- Wikipedia (biographical information)
- News articles & media
- University profiles
- YouTube transcripts
- GitHub (code contributions)
- LinkedIn (professional background)

### 4. **Professional PDF Output** ğŸ“„
- 30-50 page structured reports
- Proper formatting (headers, footers, lists, quotes)
- Markdown-to-ReportLab conversion
- Clean typography

### 5. **Paper Download & Curation** ğŸ“š
- Downloads actual PDF research papers
- Curates top 25 papers by topic relevance + citations
- Creates ZIP archives
- Filters out paywalled/polluted content

## ğŸ“‹ Installation

```bash
# Clone the repository
git clone https://github.com/abhishek-sutaria/digital-professor-research.git
cd digital-professor-research/implementations/intelligent_data_scraper

# Install dependencies
pip install -r requirements.txt

# Set up environment variable
echo "GEMINI_API_KEY=your_api_key_here" > .env
```

## ğŸ¬ Usage

### Basic Usage

```bash
python main.py "Kevin Lane Keller" --scholar-id x8xNLZQAAAAJ --wikipedia-url https://en.wikipedia.org/wiki/Kevin_Lane_Keller --output-dir ./output
```

### Available Options

- `--scholar-id`: Google Scholar user ID (for identity lock)
- `--wikipedia-url`: Direct link to Wikipedia page
- `--linkedin-url`: LinkedIn profile URL
- `--github-login`: GitHub username
- `--university-url`: University faculty page
- `--output-dir`: Output directory (default: `./output`)

### Output Files

- `{person_name}_profile.pdf` - 30-50 page comprehensive profile
- `{person_name}_papers.zip` - Curated research papers
- `{person_name}_raw_data.json` - Raw scraped data

## ğŸ—ï¸ Project Structure

```
intelligent_data_scraper/
â”œâ”€â”€ scrapers/              # Web scrapers for different sources
â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”œâ”€â”€ google_scholar_scraper.py
â”‚   â”œâ”€â”€ wikipedia_scraper.py
â”‚   â”œâ”€â”€ news_scraper.py
â”‚   â””â”€â”€ university_scraper.py
â”œâ”€â”€ processors/            # AI synthesis & PDF generation
â”‚   â”œâ”€â”€ content_synthesizer.py  # Gemini AI integration
â”‚   â”œâ”€â”€ pdf_generator.py        # Professional PDF output
â”‚   â”œâ”€â”€ text_analyzer.py        # NLP analysis
â”‚   â””â”€â”€ publications_enricher.py
â”œâ”€â”€ storage/              # Database & caching
â”‚   â””â”€â”€ cache_manager.py
â”œâ”€â”€ config.py             # Configuration
â”œâ”€â”€ main.py              # CLI application
â””â”€â”€ requirements.txt     # Dependencies
```

## ğŸ“ Example Output

For Kevin Lane Keller, the tool generates:

### PDF Sections
1. Executive Summary (2 pages)
2. Personality Profile (6-8 pages)  
3. Domain Expertise & Knowledge (12-15 pages)
   - CBBE Pyramid framework
   - Brand resonance theory
   - Integrated marketing communications
   - Brand architecture strategies
4. Professional Background (4-5 pages)
5. Writing Style Analysis (5-7 pages)
6. Thought Leadership (5-7 pages)
7. Network & Influence (3-4 pages)
8. Appendix (data sources & methodology)

### Papers ZIP
- Top 25 papers on branding/brand equity
- All papers filtered for "Kevin Lane Keller" only
- Open-access PDFs downloaded automatically

## ğŸ”¬ Technical Deep Dive

### Author Disambiguation

```python
def filter_by_exact_author(pubs, exact_name="kevin lane keller", 
                             affiliation_keywords=['dartmouth', 'tuck']):
    # Requires exact name match in authors
    # Must mention affiliation in venue/abstract
    # Reduces pollution by 95%+
```

### Curated Knowledge Extraction

```python
def score_pub(pub):
    topic_match = sum(keyword_hits for 'brand', 'brand equity', etc.)
    citations = int(pub['citations'] or 0)
    return topic_match * 1000 + citations
# Keeps highest relevance papers
```

### Fallback Synthesis

```python
if generation_fails_after_5_retries:
    fallback_prompt = "Create Domain Expertise for Kevin Lane Keller..."
    # Never returns empty section
```

## ğŸŒŸ Differentiators from Normal Web Scraping

| Feature | Normal Scraper | Intelligent Data Scraper |
|---------|---------------|-------------------------|
| **Identity Lock** | âŒ Mixed people | âœ… Exact person only |
| **AI Synthesis** | âŒ Dump raw JSON | âœ… 50-page narrative |
| **Author Verification** | âŒ Accepts all | âœ… Filters by name+affiliation |
| **Knowledge Curation** | âŒ All papers | âœ… Top 25 by relevance |
| **Academic Quality** | âŒ Basic | âœ… University-grade rigor |
| **LLM-Ready Output** | âŒ Raw dumps | âœ… Structured training data |

## ğŸ¯ Use Cases

1. **AI Training Data**: Build comprehensive knowledge bases for LLM fine-tuning
2. **Digital Twins**: Create AI replicas of expert personalities
3. **Educational Content**: Generate detailed expert profiles for learning platforms
4. **Research Support**: Curate expert knowledge for academic research
5. **Brand Reputation**: Build authoritative profiles for thought leaders

## ğŸ”‘ Key Technologies

- **Web Scraping**: BeautifulSoup4, Selenium, Scholarly, YouTube Transcript API
- **AI**: Google Gemini 2.5 Flash (content synthesis)
- **PDF Generation**: ReportLab (professional formatting)
- **NLP**: NLTK (text analysis, sentiment)
- **Database**: SQLite (caching)
- **APIs**: Crossref, Semantic Scholar (publication enrichment)

## ğŸ“Š Performance

- **Scraping Time**: 15-20 seconds (with caching)
- **AI Synthesis**: 10-15 minutes (for 30-50 page output)
- **Paper Download**: 2-5 minutes (top 25 papers)
- **Total Runtime**: ~20 minutes for complete profile

## ğŸ›¡ï¸ Safety & Ethics

- Only scrapes publicly available data
- Respects robots.txt files
- Rate limiting to avoid server overload
- Attribution to all sources
- No paywalled content downloads
- Focused on educational/research purposes

## ğŸ¤ Contributing

This is part of the larger Digital Professor research project. 

See parent repository: [digital-professor-research](https://github.com/abhishek-sutaria/digital-professor-research)

## ğŸ“ License

Part of educational research project. See parent repository for licensing.

## ğŸ“§ Contact

For questions about the Intelligent Data Scraper component:
- Open an issue in the parent repository
- Contact: abhishek-sutaria

---

**Status**: Fully Functional âœ…  
**Last Updated**: January 2025  
**Version**: 1.0.0
